# 阿里达摩院四面计算机视觉

### 1面(1h10min) - 电面

约定电面晚上8点半(阿里是加班到9、10点的节奏？）

#### 自我介绍：

#### 项目

主要是商汤无人车实习的项目，问我比baseline提升15个点，怎么来的。

从数据迭代、backbone、模型修改几个层面上说了下。

挑一两个有意思的优化说说，说了cascade、hdcnn的结构，为什么用这种结构。

项目中出现什么情况，怎么解决的？主要就是说小目标检测的解决方案。

对caffe源码熟悉程度。（我扯了扯源码的底层设计模式，数据流怎么流的，如何添加新层、cuda代码的细节）

开放题

给了一个情景，如何训练模型、调优。（题目很空，主要考察你对深度学习的理解）

根据需求（前向传播时间、模型大小），确定模型和基础网络，跑第一版模型。（举了个栗子）
判断模型是否出现过拟合的情况，来决定下一步的优化方向。
结果分析(confusionMatrix等)，分析问题，将论文中的方法套上去，如果没有自己创造。（又举了个栗子）

softmax、多个logistic的各自的优势？1、类别数爆炸，2、推了下softmax反向传播的公式，来对比两者的优劣。

算法(走流程题)
字符串判断是否是ipv4，c++。(可能是时间不多了，大佬想下班了)

#### 体会：

全程大多都是我在说，没有太多互动。后来经过源神@邢源建议，还是要故意给面试官漏点马脚让他们来怼我们，然后再怼回去，并说明不这么做的原因，不然不好拿高评分。(卧槽，真的是套路深啊～)

### 2面(1h30min) - 杭州电面

#### 项目

大佬貌似涉猎很广泛，对每一个领域都很熟悉，基本上简历中的很多细节，他都能找到点怼我。（聊了很久）

项目是从头怼到尾，主要考察对项目、深度学习的理解。

大佬对我的trickList很感兴趣，我猜想他现在做的工作和我的很相似。

Anchor大小、长宽比选取？我说了业界常用的方法(YOLO9000中的方法)，并提了一个更优的方法。

#### 如何解决小目标：

为什么要深层、浅层featureMap concat？提了点细节和我踩的坑，需要数量级上的调整，不然深层的feature可能会被压制。

Cascade的思想? 说了下我的摸索的一个过程。改变样本分布，困难样本挖掘，能达到比较好的效果。

文字识别使用ctc loss的一些细节。

#### 开放题

设计一个情景，倾斜字体检测，问我有什么好的想法？（我觉得应该是他现在遇到的问题）

数据增强，加入形变扰动。

非end-to-end版本：分别训练检测和分类，举了之前做过的一个文字识别的项目的实现。

end-to-end版本：加入仿射变换学习因子，学习字体倾斜的角度和形变。

在商汤发论文了吗？

没有，正在攒，项目比较重，但有一些work和insight，讲了下思路。（大佬听的很认真，貌似被我的故事打动了[捂脸]）

为啥要换实习？日常吹水。

评价：大佬主动评价我对模型理解挺好的，工作做的挺深的，说等下一面吧。

体会：二面面试官说话很快，思维比较敏捷，觉得和这种人讨论问题很欢畅，如果一起工作会很赞。

以后面试说话语速应该快一些，让人觉得思维比较敏捷，这个可能会有加分项吧。

### 3面(1h) - 电面

#### 项目&基础

大佬应该是搞backbone模型优化的，问了我怎么迭代基础网络的版本的，日常扯论文，自己的实验结果和理解。

前两个卷积层通道数不用很多，主要是提取边缘、颜色信息，少量的卷积核足矣。

skip connection有什么好处？推了下反向传播公式，根据链式法则，梯度可以直接作用于浅层网络。

初始学习率怎么设？这个我真的没有总结过，只是说一般使用0.01～0.1。

mobileNet、shufflenet的原理？说了下原理。

为什么mobileNet在理论上速度很快，工程上并没有特别大的提升？先说了卷积源码上的实现，两个超大矩阵相乘，可能是group操作，是一些零散的卷积操作，速度会慢。

大佬觉得不满意，说应该从内存上去考虑。申请空间？确实不太清楚。

问我看过哪些前沿的论文？说了说最近两个月的优质的论文。

扯到了tripleLoss，大佬问样本怎么选择？随机，然后就被大佬嫌弃了。装逼失败，这块确实没怎么深入研究。

为什么用multiLoss？多loss权重如何选？训练普通的模型使其收敛，打印反向传播梯度的大小，这表示该task的难度，以此作为loss的权重，然后我补充说了下可以搞一个动态的loss权重，根据一段时间窗口来决定loss的权重。

#### 开放性问题

凸优化了解吗？牛顿法、SGD、最小二乘法，各自的优势。

凸优化其他东西呢？我说只有一些零散的知识点的记忆，纯数学，没有很系统的研究。(面试官貌似数学功底很好，只能认怂)。

感觉有点虚，我尝试着往我会的地方引[捂脸]。
工程上如何对卷积操作进行优化？答：傅立叶模拟卷积。大佬不满意，说那是cudnn早就实现的，还有什么优化吗？（确实不知道，甩锅给工程组）

样本不均衡怎么处理？一个batch类别均等采样，修改loss对不同样本的权重。

#### 体会：

三面面试官懂得不少，不过最后还是过了，有时间凸优化还是要系统整理下。

### 4面(50min) - 交叉面

#### 项目

大佬应该不是做深度学习的，应该是机器学习那块的。交流中能感觉出来对这块不是很熟。挑他不会的玩命说，至少让他看到我的工作量。

#### 基础

SVM的KTT条件？说了说，说到SMO实在说不下去了。

GBDT和randomForest区别？原理角度，方差、偏差角度，过拟合角度，谈了谈之前打阿里天池的一些经验吧。

GBDT和xgboost区别？算法上工程上的优化，面试前专门看了，总结的不错，知乎，更多细节可以看看陈天奇的论文，我没看过[捂脸]，做机器学习的小伙伴最好看看。

#### 算法题

求和接近于target的连续子数组。（lintcode上有类似的题）

最后说让后面应该还有个hr面。
